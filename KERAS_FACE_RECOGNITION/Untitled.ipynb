{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1144 images belonging to 3 classes.\n",
      "Found 318 images belonging to 3 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anirudh/anaconda/envs/fyp/lib/python3.5/site-packages/ipykernel_launcher.py:167: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/home/anirudh/anaconda/envs/fyp/lib/python3.5/site-packages/ipykernel_launcher.py:167: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., callbacks=[<keras.ca..., steps_per_epoch=62.5, validation_data=<keras.pre..., epochs=100, validation_steps=12.5)`\n",
      "INFO (theano.gof.compilelock): Refreshing lock /home/anirudh/.theano/compiledir_Linux-4.13--generic-x86_64-with-debian-stretch-sid-x86_64-3.5.4-64/lock_dir/lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "['nvcc', '-shared', '-O3', '-Xlinker', '-rpath,/usr/local/cuda-8.0/lib64', '-use_fast_math', '-arch=sm_61', '-m64', '-Xcompiler', '-fno-math-errno,-Wno-unused-label,-Wno-unused-variable,-Wno-write-strings,-DCUDA_NDARRAY_CUH=mc72d035fdf91890f3b36710688069b2e,-DNPY_NO_DEPRECATED_API=NPY_1_7_API_VERSION,-fPIC,-fvisibility=hidden', '-Xlinker', '-rpath,/home/anirudh/.theano/compiledir_Linux-4.13--generic-x86_64-with-debian-stretch-sid-x86_64-3.5.4-64/cuda_ndarray', '-I/home/anirudh/.theano/compiledir_Linux-4.13--generic-x86_64-with-debian-stretch-sid-x86_64-3.5.4-64/cuda_ndarray', '-I/usr/local/cuda-8.0/include', '-I/home/anirudh/anaconda/envs/fyp/lib/python3.5/site-packages/theano/sandbox/cuda', '-I/home/anirudh/anaconda/envs/fyp/lib/python3.5/site-packages/numpy/core/include', '-I/home/anirudh/anaconda/envs/fyp/include/python3.5m', '-I/home/anirudh/anaconda/envs/fyp/lib/python3.5/site-packages/theano/gof', '-L/home/anirudh/.theano/compiledir_Linux-4.13--generic-x86_64-with-debian-stretch-sid-x86_64-3.5.4-64/cuda_ndarray', '-L/home/anirudh/anaconda/envs/fyp/lib', '-o', '/home/anirudh/.theano/compiledir_Linux-4.13--generic-x86_64-with-debian-stretch-sid-x86_64-3.5.4-64/tmpidynwxhc/md48cd7c806151b0105e1fa2b573cc03b.so', 'mod.cu', '-lcudart', '-lcublas', '-lcuda_ndarray', '-lcudnn', '-lpython3.5m']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1 #include <Python.h>\n",
      "2 #include <iostream>\n",
      "3 #include \"theano_mod_helper.h\"\n",
      "4 #include \"cuda_ndarray.cuh\"\n",
      "5 #include <math.h>\n",
      "6 #include <numpy/arrayobject.h>\n",
      "7 #include <numpy/arrayscalars.h>\n",
      "8 #include \"cudnn.h\"\n",
      "9 #include \"cudnn_helper.h\"\n",
      "10 //////////////////////\n",
      "11 ////  Support Code\n",
      "12 //////////////////////\n",
      "13 \n",
      "14 void _capsule_destructor(PyObject *o) {\n",
      "15     void *d = PyCapsule_GetContext(o);\n",
      "16     void *p = PyCapsule_GetPointer(o, NULL);\n",
      "17     void (*f)(void *) = (void (*)(void *))d;\n",
      "18     if (f != NULL) f(p);\n",
      "19 }\n",
      "20 \n",
      "21 \n",
      "22 static cudnnHandle_t _handle = NULL;\n",
      "23 \n",
      "24 \n",
      "25 static int\n",
      "26 c_set_tensorNd(CudaNdarray *var, cudnnTensorDescriptor_t desc) {\n",
      "27 \n",
      "28   int dim = CudaNdarray_NDIM(var);\n",
      "29   int *strides = (int *)malloc(dim * sizeof(int));\n",
      "30   int default_str = 1;\n",
      "31   int return_value = 0;\n",
      "32   \n",
      "33   if (strides != NULL) {\n",
      "34     for (int i = dim-1; i >= 0; i--)\n",
      "35     {\n",
      "36       if (CudaNdarray_HOST_STRIDES(var)[i])\n",
      "37         strides[i] = CudaNdarray_HOST_STRIDES(var)[i];\n",
      "38       else\n",
      "39         strides[i] = default_str;\n",
      "40       default_str *= CudaNdarray_HOST_DIMS(var)[i];\n",
      "41     }\n",
      "42     \n",
      "43     cudnnStatus_t err = cudnnSetTensorNdDescriptor(desc, CUDNN_DATA_FLOAT, dim,\n",
      "44                                                    CudaNdarray_HOST_DIMS(var),\n",
      "45                                                    strides);\n",
      "46   \t \t\t\t\t\t\t\t\t\t\n",
      "47     \n",
      "48     if (err != CUDNN_STATUS_SUCCESS) {\n",
      "49       PyErr_Format(PyExc_RuntimeError,\n",
      "50 \t\t  \"Could not set tensorNd descriptor: %s\"\n",
      "51 \t\t  \"dim=%d\",\n",
      "52 \t\t  cudnnGetErrorString(err), dim);\n",
      "53 \t\t  \n",
      "54 \t  return_value = -1;\n",
      "55     }\n",
      "56   } else {\n",
      "57     PyErr_Format(PyExc_MemoryError,\n",
      "58 \t\t\"Could not allocate memory for strides array of size %d.\",\n",
      "59 \t\tdim);\n",
      "60 \t\t\n",
      "61     return_value = -1;  \n",
      "62   }\n",
      "63     \n",
      "64   free(strides);\n",
      "65   return return_value;\n",
      "66 }\n",
      "67 \n",
      "68 \n",
      "69 static int\n",
      "70 c_set_filterNd(CudaNdarray *var, cudnnFilterDescriptor_t desc) {\n",
      "71   if (!CudaNdarray_is_c_contiguous(var)) {\n",
      "72     PyErr_SetString(PyExc_ValueError,\n",
      "73 \t\t    \"Only contiguous filters (kernels) are supported.\");\n",
      "74     return -1;\n",
      "75   }\n",
      "76   int dim = CudaNdarray_NDIM(var);\n",
      "77   cudnnStatus_t err = cudnnSetFilterNdDescriptor_v4(desc,\n",
      "78                                                     CUDNN_DATA_FLOAT,\n",
      "79                                                     CUDNN_TENSOR_NCHW,\n",
      "80                                                     dim,\n",
      "81                                                     CudaNdarray_HOST_DIMS(var));\n",
      "82   if (err != CUDNN_STATUS_SUCCESS) {\n",
      "83     PyErr_Format(PyExc_RuntimeError,\n",
      "84 \t\t \"Could not set filter descriptor: %s.\"\n",
      "85 \t\t \" dims= %d\",\n",
      "86 \t\t cudnnGetErrorString(err), dim);\n",
      "87     return -1;\n",
      "88   }\n",
      "89   return 0;\n",
      "90 }\n",
      "91 \n",
      "92 \n",
      "93 \n",
      "94     namespace {\n",
      "95     struct __struct_compiled_op_md48cd7c806151b0105e1fa2b573cc03b {\n",
      "96         PyObject* __ERROR;\n",
      "97 \n",
      "98         PyObject* storage_V3;\n",
      "99 PyObject* storage_V5;\n",
      "100 PyObject* storage_V7;\n",
      "101 PyObject* storage_V9;\n",
      "102 PyObject* storage_V11;\n",
      "103 PyObject* storage_V13;\n",
      "104 PyObject* storage_V1;\n",
      "105         \n",
      "106 #define DTYPE_INPUT_0 npy_float32\n",
      "107 #define TYPENUM_INPUT_0 11\n",
      "108 #define ITEMSIZE_INPUT_0 4\n",
      "109 #define DTYPE_INPUT_1 npy_float32\n",
      "110 #define TYPENUM_INPUT_1 11\n",
      "111 #define ITEMSIZE_INPUT_1 4\n",
      "112 #define DTYPE_INPUT_2 npy_float32\n",
      "113 #define TYPENUM_INPUT_2 11\n",
      "114 #define ITEMSIZE_INPUT_2 4\n",
      "115 #define DTYPE_INPUT_4 npy_float32\n",
      "116 #define TYPENUM_INPUT_4 11\n",
      "117 #define ITEMSIZE_INPUT_4 4\n",
      "118 #define DTYPE_INPUT_5 npy_float32\n",
      "119 #define TYPENUM_INPUT_5 11\n",
      "120 #define ITEMSIZE_INPUT_5 4\n",
      "121 #define DTYPE_OUTPUT_0 npy_float32\n",
      "122 #define TYPENUM_OUTPUT_0 11\n",
      "123 #define ITEMSIZE_OUTPUT_0 4\n",
      "124 #define APPLY_SPECIFIC(str) str##_node_md48cd7c806151b0105e1fa2b573cc03b_0\n",
      "125 #define CONV_ALGO CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM\n",
      "126 #define CHOOSE_ALGO 0\n",
      "127 #define CHOOSE_ALGO_ONCE 0\n",
      "128 #define CHOOSE_ALGO_TIME 0\n",
      "129 #define CONV_INPLACE 1\n",
      "130 \n",
      "131 cudnnTensorDescriptor_t APPLY_SPECIFIC(input);\n",
      "132 cudnnTensorDescriptor_t APPLY_SPECIFIC(output);\n",
      "133 cudnnFilterDescriptor_t APPLY_SPECIFIC(kerns);\n",
      "134 \n",
      "135 /* Keep track, from one execution to another, of the dimension of the data\n",
      "136 and the algorithms, if any, that were selected according to these dimensions\n",
      "137 and according to the amount of memory available at that time.\n",
      "138 \n",
      "139 Note : Implementation selection for backward convolution only exists starting\n",
      "140 at V3.\n",
      "141 */\n",
      "142 int APPLY_SPECIFIC(previous_input_shape)[5];\n",
      "143 int APPLY_SPECIFIC(previous_kerns_shape)[5];\n",
      "144 int APPLY_SPECIFIC(previous_output_shape)[5];\n",
      "145 bool APPLY_SPECIFIC(previous_algo_set);\n",
      "146 cudnnConvolutionFwdAlgo_t APPLY_SPECIFIC(previous_algo);\n",
      "147 cudnnConvolutionBwdFilterAlgo_t APPLY_SPECIFIC(previous_bwd_f_algo);\n",
      "148 cudnnConvolutionBwdDataAlgo_t APPLY_SPECIFIC(previous_bwd_d_algo);\n",
      "149 \n",
      "150 \n",
      "151 \n",
      "152 int\n",
      "153 APPLY_SPECIFIC(conv_fwd)(CudaNdarray *input, CudaNdarray *kerns,\n",
      "154                          CudaNdarray *om, cudnnConvolutionDescriptor_t desc,\n",
      "155                          float alpha, float beta, CudaNdarray **output) {\n",
      "156 \n",
      "157   cudnnStatus_t err = CUDNN_STATUS_SUCCESS;\n",
      "158   if (CudaNdarray_HOST_DIMS(input)[1] != CudaNdarray_HOST_DIMS(kerns)[1]) {\n",
      "159     PyErr_SetString(PyExc_ValueError,\n",
      "160                     \"GpuDnnConv images and kernel must have the same stack size\\n\");\n",
      "161     return 1;\n",
      "162   }\n",
      "163 \n",
      "164   int nb_dim = CudaNdarray_NDIM(input);\n",
      "165 \n",
      "166 #ifdef CONV_INPLACE\n",
      "167   Py_XDECREF(*output);\n",
      "168   *output = om;\n",
      "169   Py_INCREF(*output);\n",
      "170 #else\n",
      "171   if (CudaNdarray_prep_output(output, nb_dim, CudaNdarray_HOST_DIMS(om)) != 0)\n",
      "172     return 1;\n",
      "173   if (beta != 0.0 && CudaNdarray_CopyFromCudaNdarray(*output, om))\n",
      "174     return 1;\n",
      "175 #endif\n",
      "176 \n",
      "177   if (CudaNdarray_DIMS(input)[0] == 0 || CudaNdarray_DIMS(kerns)[0] == 0 || CudaNdarray_DIMS(kerns)[1] == 0) {\n",
      "178     cudaError_t err2 = cudaMemset((*output)->devdata, 0,\n",
      "179                                   CudaNdarray_SIZE(*output) * sizeof(real));\n",
      "180     if (err2 != cudaSuccess) {\n",
      "181       PyErr_Format(PyExc_RuntimeError,\n",
      "182                    \"GpuDnnConv could not fill the output with zeros: %s\",\n",
      "183                    cudaGetErrorString(err2));\n",
      "184       return 1;\n",
      "185     }\n",
      "186     return 0;\n",
      "187   }\n",
      "188 \n",
      "189   if (c_set_tensorNd(input, APPLY_SPECIFIC(input)) == -1)\n",
      "190     return 1;\n",
      "191   if (c_set_filterNd(kerns, APPLY_SPECIFIC(kerns)) == -1)\n",
      "192     return 1;\n",
      "193   if (c_set_tensorNd(*output, APPLY_SPECIFIC(output)) == -1)\n",
      "194     return 1;\n",
      "195 \n",
      "196   {\n",
      "197     size_t worksize;\n",
      "198     void *workspace;\n",
      "199     cudnnConvolutionFwdAlgo_t chosen_algo;\n",
      "200 \n",
      "201 \n",
      "202     if (CHOOSE_ALGO)\n",
      "203     {\n",
      "204 \n",
      "205       // A new convolution implementation should be selected, based either on\n",
      "206       // timing or heuristics if in one of the two following cases :\n",
      "207       // - The implementation should only be chosen during the first execution\n",
      "208       //   of an apply node and this is the first execution of the apply node.\n",
      "209       // - The implementation should be chosen as often as necessary and the\n",
      "210       //   shapes of the inputs differ from the last time an implementation\n",
      "211       //   was chosen.\n",
      "212       bool reuse_previous_algo;\n",
      "213       if (CHOOSE_ALGO_ONCE)\n",
      "214       {\n",
      "215         // Only choose a new implementation of none has been chosen before.\n",
      "216         reuse_previous_algo = APPLY_SPECIFIC(previous_algo_set);\n",
      "217       }\n",
      "218       else\n",
      "219       {\n",
      "220         // Reuse the previous implementation if the inputs and the kernels\n",
      "221         // have the same shapes as they had when the previous implementation\n",
      "222         // was selected\n",
      "223         bool same_shapes = true;\n",
      "224         for (int i = 0; (i < nb_dim) && same_shapes; i++)\n",
      "225         {\n",
      "226           same_shapes &= (CudaNdarray_HOST_DIMS(input)[i] ==\n",
      "227                           APPLY_SPECIFIC(previous_input_shape)[i]);\n",
      "228           same_shapes &= (CudaNdarray_HOST_DIMS(kerns)[i] ==\n",
      "229                           APPLY_SPECIFIC(previous_kerns_shape)[i]);\n",
      "230         }\n",
      "231         reuse_previous_algo = same_shapes;\n",
      "232       }\n",
      "233 \n",
      "234       // If the previously choosen implementation can't be reused, select a\n",
      "235       // new one based on the shapes of the current inputs\n",
      "236       if (!reuse_previous_algo)\n",
      "237       {\n",
      "238 \n",
      "239         // Obtain a convolution algorithm appropriate for the input and kernel\n",
      "240         // shapes. Either by choosing one according to heuristics or by making\n",
      "241         // cuDNN time every implementation and choose the best one.\n",
      "242         if (CHOOSE_ALGO_TIME)\n",
      "243         {\n",
      "244           // Time the different implementations to choose the best one\n",
      "245           int requestedCount = 1;\n",
      "246           int count;\n",
      "247           cudnnConvolutionFwdAlgoPerf_t choosen_algo_perf;\n",
      "248           err = cudnnFindConvolutionForwardAlgorithm(_handle,\n",
      "249                                                      APPLY_SPECIFIC(input),\n",
      "250                                                      APPLY_SPECIFIC(kerns),\n",
      "251                                                      desc,\n",
      "252                                                      APPLY_SPECIFIC(output),\n",
      "253                                                      requestedCount,\n",
      "254                                                      &count,\n",
      "255                                                      &choosen_algo_perf);\n",
      "256           if (err != CUDNN_STATUS_SUCCESS) {\n",
      "257             PyErr_Format(PyExc_RuntimeError,\n",
      "258                          \"GpuDnnConv: error selecting convolution algo: %s\",\n",
      "259                          cudnnGetErrorString(err));\n",
      "260             return 1;\n",
      "261           }\n",
      "262 \n",
      "263           chosen_algo = choosen_algo_perf.algo;\n",
      "264         }\n",
      "265         else\n",
      "266         {\n",
      "267           // The implementation should be chosen using heuristics based on the\n",
      "268           // input shapes and the amount of memory available.\n",
      "269 \n",
      "270           // Get the amount of available memory\n",
      "271           size_t free = 0, total = 0;\n",
      "272           cudaError_t err2 = cudaMemGetInfo(&free, &total);\n",
      "273           if (err2 != cudaSuccess){\n",
      "274             cudaGetLastError();\n",
      "275             fprintf(stderr,\n",
      "276                     \"Error when trying to find the memory information\"\n",
      "277                     \" on the GPU: %s\\n\", cudaGetErrorString(err2));\n",
      "278             return 1;\n",
      "279           }\n",
      "280 \n",
      "281           // Use heuristics to choose the implementation\n",
      "282           err = cudnnGetConvolutionForwardAlgorithm(_handle,\n",
      "283                                                     APPLY_SPECIFIC(input),\n",
      "284                                                     APPLY_SPECIFIC(kerns),\n",
      "285                                                     desc,\n",
      "286                                                     APPLY_SPECIFIC(output),\n",
      "287                                                     CUDNN_CONVOLUTION_FWD_SPECIFY_WORKSPACE_LIMIT,\n",
      "288                                                     free,\n",
      "289                                                     &chosen_algo);\n",
      "290 \n",
      "291           if (err != CUDNN_STATUS_SUCCESS) {\n",
      "292             PyErr_Format(PyExc_RuntimeError,\n",
      "293                          \"GpuDnnConv: error selecting convolution algo: %s\",\n",
      "294                          cudnnGetErrorString(err));\n",
      "295             return 1;\n",
      "296           }\n",
      "297         }\n",
      "298 \n",
      "299         // Store the shapes of the inputs and kernels as well as the chosen\n",
      "300         // algorithm for future use.\n",
      "301         APPLY_SPECIFIC(previous_algo) = chosen_algo;\n",
      "302         APPLY_SPECIFIC(previous_algo_set) = true;\n",
      "303         for (int i = 0; i < nb_dim; i++)\n",
      "304         {\n",
      "305             APPLY_SPECIFIC(previous_input_shape)[i] =\n",
      "306                                             CudaNdarray_HOST_DIMS(input)[i];\n",
      "307             APPLY_SPECIFIC(previous_kerns_shape)[i] =\n",
      "308                                             CudaNdarray_HOST_DIMS(kerns)[i];\n",
      "309         }\n",
      "310       }\n",
      "311       else\n",
      "312       {\n",
      "313           // Reuse the previously chosen convolution implementation\n",
      "314           chosen_algo = APPLY_SPECIFIC(previous_algo);\n",
      "315       }\n",
      "316     }\n",
      "317     else\n",
      "318     {\n",
      "319       chosen_algo = CONV_ALGO;\n",
      "320     }\n",
      "321 \n",
      "322     if (0){\n",
      "323       char * a;\n",
      "324       switch(chosen_algo){\n",
      "325       case CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM:\n",
      "326 \ta = \"implicit gemm (0)\";\n",
      "327 \tbreak;\n",
      "328       case CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM:\n",
      "329 \ta = \"precomp gemm (1)\";\n",
      "330 \tbreak;\n",
      "331       case CUDNN_CONVOLUTION_FWD_ALGO_GEMM:\n",
      "332 \ta = \"gemm (2)\";\n",
      "333 \tbreak;\n",
      "334       case CUDNN_CONVOLUTION_FWD_ALGO_DIRECT:\n",
      "335 \ta = \"direct (3)\";\n",
      "336 \tbreak;\n",
      "337       case CUDNN_CONVOLUTION_FWD_ALGO_FFT:\n",
      "338 \ta = \"fft (4)\";\n",
      "339 \tbreak;\n",
      "340       case CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING:\n",
      "341 \ta = \"fft tiling (5)\";\n",
      "342 \tbreak;\n",
      "343 #if CUDNN_VERSION > 5000\n",
      "344       case CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD:\n",
      "345 \ta = \"winograd (6)\";\n",
      "346 \tbreak;\n",
      "347 #endif\n",
      "348       }\n",
      "349       printf(\"GpuDNNConv: algo %s\\n\", a);\n",
      "350     }\n",
      "351 \n",
      "352     // The FFT implementation (only in V3 and onward) does not support strides,\n",
      "353     // 1x1 filters or inputs with a spatial dimension larger than 1024.\n",
      "354     // The tiled-FFT implementation (only in V4 onward) does not support\n",
      "355     // strides.\n",
      "356     // If the chosen implementation is FFT or tiled-FFT, validate that it can\n",
      "357     // be used on the current data and default on a safe implementation if it\n",
      "358     // can't.\n",
      "359     // Following code is 2d-specific, but it is fine as FFT and tiled-FFT are\n",
      "360     // defined only for 2d-filters\n",
      "361     if ((chosen_algo == CUDNN_CONVOLUTION_FWD_ALGO_FFT ||\n",
      "362          chosen_algo == CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING) && nb_dim == 4)\n",
      "363     {\n",
      "364 \n",
      "365       // Extract the properties of the convolution descriptor\n",
      "366       int nd;\n",
      "367       int pad[2];\n",
      "368       int stride[2];\n",
      "369       int upscale[2];\n",
      "370       cudnnConvolutionMode_t mode;\n",
      "371       cudnnDataType_t data_type;\n",
      "372       err = cudnnGetConvolutionNdDescriptor(desc, 2, &nd, pad, stride,\n",
      "373                                             upscale, &mode, &data_type);\n",
      "374 \n",
      "375       if (err != CUDNN_STATUS_SUCCESS) {\n",
      "376         PyErr_Format(PyExc_RuntimeError,\n",
      "377                      \"GpuDnnConv: error getting convolution properties: %s\",\n",
      "378                      cudnnGetErrorString(err));\n",
      "379         return 1;\n",
      "380       }\n",
      "381 \n",
      "382       // Extract the spatial size of the filters\n",
      "383       int filter_h = CudaNdarray_HOST_DIMS(kerns)[2];\n",
      "384       int filter_w = CudaNdarray_HOST_DIMS(kerns)[3];\n",
      "385 \n",
      "386       // Extract the spatial size of the input\n",
      "387       int input_h = CudaNdarray_HOST_DIMS(input)[2];\n",
      "388       int input_w = CudaNdarray_HOST_DIMS(input)[3];\n",
      "389 \n",
      "390       // Ensure that the selected implementation supports the requested\n",
      "391       // convolution. Fall back to a safe implementation otherwise.\n",
      "392       if (chosen_algo == CUDNN_CONVOLUTION_FWD_ALGO_FFT)\n",
      "393       {\n",
      "394         if (stride[0] != 1 || stride[1] != 1 || input_h > 1024 ||\n",
      "395             input_w > 1024 || (filter_h == 1 && filter_w == 1))\n",
      "396         {\n",
      "397           chosen_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;\n",
      "398         }\n",
      "399       }\n",
      "400       else\n",
      "401       {\n",
      "402         // chosen_algo == CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING\n",
      "403         if (stride[0] != 1 || stride[1] != 1)\n",
      "404         {\n",
      "405           chosen_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;\n",
      "406         }\n",
      "407       }\n",
      "408     }\n",
      "409 \n",
      "410     err = cudnnGetConvolutionForwardWorkspaceSize(_handle,\n",
      "411                                                   APPLY_SPECIFIC(input),\n",
      "412                                                   APPLY_SPECIFIC(kerns),\n",
      "413                                                   desc,\n",
      "414                                                   APPLY_SPECIFIC(output),\n",
      "415                                                   chosen_algo,\n",
      "416                                                   &worksize);\n",
      "417     if (err == CUDNN_STATUS_NOT_SUPPORTED) {\n",
      "418       // Fallback to none algo if not supported\n",
      "419       // TODO: Print a warning\n",
      "420       chosen_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;\n",
      "421 \n",
      "422       err = cudnnGetConvolutionForwardWorkspaceSize(_handle,\n",
      "423                                                     APPLY_SPECIFIC(input),\n",
      "424                                                     APPLY_SPECIFIC(kerns),\n",
      "425                                                     desc,\n",
      "426                                                     APPLY_SPECIFIC(output),\n",
      "427                                                     chosen_algo,\n",
      "428                                                     &worksize);\n",
      "429     }\n",
      "430     if (err != CUDNN_STATUS_SUCCESS) {\n",
      "431       PyErr_Format(PyExc_RuntimeError,\n",
      "432                    \"GpuDnnConv: error getting worksize: %s\",\n",
      "433                    cudnnGetErrorString(err));\n",
      "434       return 1;\n",
      "435     }\n",
      "436     workspace = get_work_mem(worksize);\n",
      "437     if (workspace == NULL && worksize != 0)\n",
      "438       return 1;\n",
      "439 \n",
      "440     err = cudnnConvolutionForward(\n",
      "441       _handle,\n",
      "442       (void *)&alpha,\n",
      "443       APPLY_SPECIFIC(input), CudaNdarray_DEV_DATA(input),\n",
      "444       APPLY_SPECIFIC(kerns), CudaNdarray_DEV_DATA(kerns),\n",
      "445       desc,\n",
      "446       chosen_algo,\n",
      "447       workspace, worksize,\n",
      "448       (void *)&beta,\n",
      "449       APPLY_SPECIFIC(output), CudaNdarray_DEV_DATA(*output));\n",
      "450   }\n",
      "451   if (err != CUDNN_STATUS_SUCCESS) {\n",
      "452     PyErr_Format(PyExc_RuntimeError, \"GpuDnnConv: error doing operation: %s\",\n",
      "453 \t\t cudnnGetErrorString(err));\n",
      "454     return 1;\n",
      "455   }\n",
      "456   return 0;\n",
      "457 }\n",
      "458 \n",
      "459 #undef DTYPE_INPUT_0\n",
      "460 #undef TYPENUM_INPUT_0\n",
      "461 #undef ITEMSIZE_INPUT_0\n",
      "462 #undef DTYPE_INPUT_1\n",
      "463 #undef TYPENUM_INPUT_1\n",
      "464 #undef ITEMSIZE_INPUT_1\n",
      "465 #undef DTYPE_INPUT_2\n",
      "466 #undef TYPENUM_INPUT_2\n",
      "467 #undef ITEMSIZE_INPUT_2\n",
      "468 #undef DTYPE_INPUT_4\n",
      "469 #undef TYPENUM_INPUT_4\n",
      "470 #undef ITEMSIZE_INPUT_4\n",
      "471 #undef DTYPE_INPUT_5\n",
      "472 #undef TYPENUM_INPUT_5\n",
      "473 #undef ITEMSIZE_INPUT_5\n",
      "474 #undef DTYPE_OUTPUT_0\n",
      "475 #undef TYPENUM_OUTPUT_0\n",
      "476 #undef ITEMSIZE_OUTPUT_0\n",
      "477 #undef APPLY_SPECIFIC\n",
      "478 #undef CONV_ALGO\n",
      "479 #undef CHOOSE_ALGO\n",
      "480 #undef CHOOSE_ALGO_ONCE\n",
      "481 #undef CHOOSE_ALGO_TIME\n",
      "482 #undef CONV_INPLACE\n",
      "483 \n",
      "484         __struct_compiled_op_md48cd7c806151b0105e1fa2b573cc03b() {\n",
      "485             // This is only somewhat safe because we:\n",
      "486             //  1) Are not a virtual class\n",
      "487             //  2) Do not use any virtual classes in the members\n",
      "488             //  3) Deal with mostly POD and pointers\n",
      "489 \n",
      "490             // If this changes, we would have to revise this, but for\n",
      "491             // now I am tired of chasing segfaults because\n",
      "492             // initialization code had an error and some pointer has\n",
      "493             // a junk value.\n",
      "494             memset(this, 0, sizeof(*this));\n",
      "495         }\n",
      "496         ~__struct_compiled_op_md48cd7c806151b0105e1fa2b573cc03b(void) {\n",
      "497             cleanup();\n",
      "498         }\n",
      "499 \n",
      "500         int init(PyObject* __ERROR, PyObject* storage_V3, PyObject* storage_V5, PyObject* storage_V7, PyObject* storage_V9, PyObject* storage_V11, PyObject* storage_V13, PyObject* storage_V1) {\n",
      "501             Py_XINCREF(storage_V3);\n",
      "502 Py_XINCREF(storage_V5);\n",
      "503 Py_XINCREF(storage_V7);\n",
      "504 Py_XINCREF(storage_V9);\n",
      "505 Py_XINCREF(storage_V11);\n",
      "506 Py_XINCREF(storage_V13);\n",
      "507 Py_XINCREF(storage_V1);\n",
      "508             this->storage_V3 = storage_V3;\n",
      "509 this->storage_V5 = storage_V5;\n",
      "510 this->storage_V7 = storage_V7;\n",
      "511 this->storage_V9 = storage_V9;\n",
      "512 this->storage_V11 = storage_V11;\n",
      "513 this->storage_V13 = storage_V13;\n",
      "514 this->storage_V1 = storage_V1;\n",
      "515             \n",
      "516 \n",
      "517 \n",
      "518 \n",
      "519 \n",
      "520 \n",
      "521 \n",
      "522 \n",
      "523 \n",
      "524 #define DTYPE_INPUT_0 npy_float32\n",
      "525 #define TYPENUM_INPUT_0 11\n",
      "526 #define ITEMSIZE_INPUT_0 4\n",
      "527 #define DTYPE_INPUT_1 npy_float32\n",
      "528 #define TYPENUM_INPUT_1 11\n",
      "529 #define ITEMSIZE_INPUT_1 4\n",
      "530 #define DTYPE_INPUT_2 npy_float32\n",
      "531 #define TYPENUM_INPUT_2 11\n",
      "532 #define ITEMSIZE_INPUT_2 4\n",
      "533 #define DTYPE_INPUT_4 npy_float32\n",
      "534 #define TYPENUM_INPUT_4 11\n",
      "535 #define ITEMSIZE_INPUT_4 4\n",
      "536 #define DTYPE_INPUT_5 npy_float32\n",
      "537 #define TYPENUM_INPUT_5 11\n",
      "538 #define ITEMSIZE_INPUT_5 4\n",
      "539 #define DTYPE_OUTPUT_0 npy_float32\n",
      "540 #define TYPENUM_OUTPUT_0 11\n",
      "541 #define ITEMSIZE_OUTPUT_0 4\n",
      "542 #define APPLY_SPECIFIC(str) str##_node_md48cd7c806151b0105e1fa2b573cc03b_0\n",
      "543 #define CONV_ALGO CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM\n",
      "544 #define CHOOSE_ALGO 0\n",
      "545 #define CHOOSE_ALGO_ONCE 0\n",
      "546 #define CHOOSE_ALGO_TIME 0\n",
      "547 #define CONV_INPLACE 1\n",
      "548 #define FAIL { \\\n",
      "549         if (!PyErr_Occurred()) { \\\n",
      "550             PyErr_SetString(PyExc_RuntimeError, \\\n",
      "551                 \"Unexpected error in an Op's C code. \" \\\n",
      "552                 \"No Python exception was set.\"); \\\n",
      "553             } \\\n",
      "554         return 15; \\\n",
      "555 }\n",
      "556 \n",
      "557 \n",
      "558 cudnnStatus_t APPLY_SPECIFIC(err);\n",
      "559 APPLY_SPECIFIC(input) = NULL;\n",
      "560 APPLY_SPECIFIC(output) = NULL;\n",
      "561 APPLY_SPECIFIC(kerns) = NULL;\n",
      "562 if ((APPLY_SPECIFIC(err) = cudnnCreateTensorDescriptor(&APPLY_SPECIFIC(input))) != CUDNN_STATUS_SUCCESS) {\n",
      "563   PyErr_Format(PyExc_MemoryError, \"could not allocate tensor descriptor \"\n",
      "564 \t       \"(inp): %s\", cudnnGetErrorString(APPLY_SPECIFIC(err)));\n",
      "565   FAIL;\n",
      "566 }\n",
      "567 if ((APPLY_SPECIFIC(err) = cudnnCreateTensorDescriptor(&APPLY_SPECIFIC(output))) != CUDNN_STATUS_SUCCESS) {\n",
      "568   PyErr_Format(PyExc_MemoryError, \"could not allocate tensor descriptor \"\n",
      "569                \"(out): %s\", cudnnGetErrorString(APPLY_SPECIFIC(err)));\n",
      "570   FAIL;\n",
      "571 }\n",
      "572 if ((APPLY_SPECIFIC(err) = cudnnCreateFilterDescriptor(&APPLY_SPECIFIC(kerns))) != CUDNN_STATUS_SUCCESS) {\n",
      "573   PyErr_Format(PyExc_MemoryError, \"could not allocate filter descriptor: %s\",\n",
      "574 \t       cudnnGetErrorString(APPLY_SPECIFIC(err)));\n",
      "575   FAIL;\n",
      "576 }\n",
      "577 \n",
      "578 for (int i = 0; i < 5; i++)\n",
      "579 {\n",
      "580   APPLY_SPECIFIC(previous_input_shape)[i] = 0;\n",
      "581   APPLY_SPECIFIC(previous_kerns_shape)[i] = 0;\n",
      "582   APPLY_SPECIFIC(previous_output_shape)[i] = 0;\n",
      "583 }\n",
      "584 \n",
      "585 APPLY_SPECIFIC(previous_algo_set) = false;\n",
      "586 \n",
      "587 // Select default implementations for the case where the convolution\n",
      "588 // implementations should be selected based on the size of the data.\n",
      "589 APPLY_SPECIFIC(previous_algo) = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM;\n",
      "590 APPLY_SPECIFIC(previous_bwd_f_algo) = CUDNN_CONVOLUTION_BWD_FILTER_ALGO_0;\n",
      "591 APPLY_SPECIFIC(previous_bwd_d_algo) = CUDNN_CONVOLUTION_BWD_DATA_ALGO_0;\n",
      "592 \n",
      "593 \n",
      "594 #undef FAIL\n",
      "595 #undef DTYPE_INPUT_0\n",
      "596 #undef TYPENUM_INPUT_0\n",
      "597 #undef ITEMSIZE_INPUT_0\n",
      "598 #undef DTYPE_INPUT_1\n",
      "599 #undef TYPENUM_INPUT_1\n",
      "600 #undef ITEMSIZE_INPUT_1\n",
      "601 #undef DTYPE_INPUT_2\n",
      "602 #undef TYPENUM_INPUT_2\n",
      "603 #undef ITEMSIZE_INPUT_2\n",
      "604 #undef DTYPE_INPUT_4\n",
      "605 #undef TYPENUM_INPUT_4\n",
      "606 #undef ITEMSIZE_INPUT_4\n",
      "607 #undef DTYPE_INPUT_5\n",
      "608 #undef TYPENUM_INPUT_5\n",
      "609 #undef ITEMSIZE_INPUT_5\n",
      "610 #undef DTYPE_OUTPUT_0\n",
      "611 #undef TYPENUM_OUTPUT_0\n",
      "612 #undef ITEMSIZE_OUTPUT_0\n",
      "613 #undef APPLY_SPECIFIC\n",
      "614 #undef CONV_ALGO\n",
      "615 #undef CHOOSE_ALGO\n",
      "616 #undef CHOOSE_ALGO_ONCE\n",
      "617 #undef CHOOSE_ALGO_TIME\n",
      "618 #undef CONV_INPLACE\n",
      "619             this->__ERROR = __ERROR;\n",
      "620             return 0;\n",
      "621         }\n",
      "622         void cleanup(void) {\n",
      "623             __label_1:\n",
      "624 \n",
      "625 double __DUMMY_1;\n",
      "626 __label_3:\n",
      "627 \n",
      "628 double __DUMMY_3;\n",
      "629 __label_5:\n",
      "630 \n",
      "631 double __DUMMY_5;\n",
      "632 __label_7:\n",
      "633 \n",
      "634 double __DUMMY_7;\n",
      "635 __label_9:\n",
      "636 \n",
      "637 double __DUMMY_9;\n",
      "638 __label_11:\n",
      "639 \n",
      "640 double __DUMMY_11;\n",
      "641 __label_13:\n",
      "642 \n",
      "643 double __DUMMY_13;\n",
      "644 __label_16:\n",
      "645 \n",
      "646 #define DTYPE_INPUT_0 npy_float32\n",
      "647 #define TYPENUM_INPUT_0 11\n",
      "648 #define ITEMSIZE_INPUT_0 4\n",
      "649 #define DTYPE_INPUT_1 npy_float32\n",
      "650 #define TYPENUM_INPUT_1 11\n",
      "651 #define ITEMSIZE_INPUT_1 4\n",
      "652 #define DTYPE_INPUT_2 npy_float32\n",
      "653 #define TYPENUM_INPUT_2 11\n",
      "654 #define ITEMSIZE_INPUT_2 4\n",
      "655 #define DTYPE_INPUT_4 npy_float32\n",
      "656 #define TYPENUM_INPUT_4 11\n",
      "657 #define ITEMSIZE_INPUT_4 4\n",
      "658 #define DTYPE_INPUT_5 npy_float32\n",
      "659 #define TYPENUM_INPUT_5 11\n",
      "660 #define ITEMSIZE_INPUT_5 4\n",
      "661 #define DTYPE_OUTPUT_0 npy_float32\n",
      "662 #define TYPENUM_OUTPUT_0 11\n",
      "663 #define ITEMSIZE_OUTPUT_0 4\n",
      "664 #define APPLY_SPECIFIC(str) str##_node_md48cd7c806151b0105e1fa2b573cc03b_0\n",
      "665 #define CONV_ALGO CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM\n",
      "666 #define CHOOSE_ALGO 0\n",
      "667 #define CHOOSE_ALGO_ONCE 0\n",
      "668 #define CHOOSE_ALGO_TIME 0\n",
      "669 #define CONV_INPLACE 1\n",
      "670 \n",
      "671 \n",
      "672 if (APPLY_SPECIFIC(input) != NULL)\n",
      "673   cudnnDestroyTensorDescriptor(APPLY_SPECIFIC(input));\n",
      "674 if (APPLY_SPECIFIC(output) != NULL)\n",
      "675   cudnnDestroyTensorDescriptor(APPLY_SPECIFIC(output));\n",
      "676 if (APPLY_SPECIFIC(kerns) != NULL)\n",
      "677   cudnnDestroyFilterDescriptor(APPLY_SPECIFIC(kerns));\n",
      "678 \n",
      "679 #undef DTYPE_INPUT_0\n",
      "680 #undef TYPENUM_INPUT_0\n",
      "681 #undef ITEMSIZE_INPUT_0\n",
      "682 #undef DTYPE_INPUT_1\n",
      "683 #undef TYPENUM_INPUT_1\n",
      "684 #undef ITEMSIZE_INPUT_1\n",
      "685 #undef DTYPE_INPUT_2\n",
      "686 #undef TYPENUM_INPUT_2\n",
      "687 #undef ITEMSIZE_INPUT_2\n",
      "688 #undef DTYPE_INPUT_4\n",
      "689 #undef TYPENUM_INPUT_4\n",
      "690 #undef ITEMSIZE_INPUT_4\n",
      "691 #undef DTYPE_INPUT_5\n",
      "692 #undef TYPENUM_INPUT_5\n",
      "693 #undef ITEMSIZE_INPUT_5\n",
      "694 #undef DTYPE_OUTPUT_0\n",
      "695 #undef TYPENUM_OUTPUT_0\n",
      "696 #undef ITEMSIZE_OUTPUT_0\n",
      "697 #undef APPLY_SPECIFIC\n",
      "698 #undef CONV_ALGO\n",
      "699 #undef CHOOSE_ALGO\n",
      "700 #undef CHOOSE_ALGO_ONCE\n",
      "701 #undef CHOOSE_ALGO_TIME\n",
      "702 #undef CONV_INPLACE\n",
      "703 double __DUMMY_16;\n",
      "704 \n",
      "705             Py_XDECREF(this->storage_V3);\n",
      "706 Py_XDECREF(this->storage_V5);\n",
      "707 Py_XDECREF(this->storage_V7);\n",
      "708 Py_XDECREF(this->storage_V9);\n",
      "709 Py_XDECREF(this->storage_V11);\n",
      "710 Py_XDECREF(this->storage_V13);\n",
      "711 Py_XDECREF(this->storage_V1);\n",
      "712         }\n",
      "713         int run(void) {\n",
      "714             int __failure = 0;\n",
      "715             \n",
      "716     PyObject* py_V1;\n",
      "717      CudaNdarray * V1;\n",
      "718     PyObject* py_V3;\n",
      "719      CudaNdarray * V3;\n",
      "720     PyObject* py_V5;\n",
      "721      CudaNdarray * V5;\n",
      "722     PyObject* py_V7;\n",
      "723      CudaNdarray * V7;\n",
      "724     PyObject* py_V9;\n",
      "725     \n",
      "726         cudnnConvolutionDescriptor_t V9;\n",
      "727         \n",
      "728     PyObject* py_V11;\n",
      "729     \n",
      "730                 typedef npy_float32 dtype_V11;\n",
      "731             \n",
      "732         npy_float32 V11;\n",
      "733         \n",
      "734     PyObject* py_V13;\n",
      "735     \n",
      "736                 typedef npy_float32 dtype_V13;\n",
      "737             \n",
      "738         npy_float32 V13;\n",
      "739         \n",
      "740 {\n",
      "741 \n",
      "742     py_V1 = PyList_GET_ITEM(storage_V1, 0);\n",
      "743     {Py_XINCREF(py_V1);}\n",
      "744     \n",
      "745         if (py_V1 == Py_None)\n",
      "746         {\n",
      "747             V1 = NULL;\n",
      "748         }\n",
      "749         else\n",
      "750         {\n",
      "751             \n",
      "752         assert(py_V1->ob_refcnt >= 2); // There should be at least one ref from the container object,\n",
      "753         // and one ref from the local scope.\n",
      "754 \n",
      "755         if (CudaNdarray_Check(py_V1))\n",
      "756         {\n",
      "757             //fprintf(stderr, \"c_extract CNDA object w refcnt %p %i\\n\", py_V1, (py_V1->ob_refcnt));\n",
      "758             V1 = (CudaNdarray*)py_V1;\n",
      "759             //std::cerr << \"c_extract \" << V1 << '\\n';\n",
      "760         \n",
      "761 \n",
      "762                 if (V1->nd != 4)\n",
      "763                 {\n",
      "764                     PyErr_Format(PyExc_RuntimeError,\n",
      "765                                  \"c_extract: Some CudaNdarray has rank %i, it was supposed to have rank 4\",\n",
      "766                                  V1->nd);\n",
      "767                     V1 = NULL;\n",
      "768                     {\n",
      "769         __failure = 2;\n",
      "770         if (!PyErr_Occurred()) {\n",
      "771             PyErr_SetString(PyExc_RuntimeError,\n",
      "772                 \"Unexpected error in an Op's C code. \"\n",
      "773                 \"No Python exception was set.\");\n",
      "774             }\n",
      "775         goto __label_2;};\n",
      "776                 }\n",
      "777                 //std::cerr << \"c_extract \" << V1 << \" nd check passed\\n\";\n",
      "778             \n",
      "779 \n",
      "780                 assert(V1);\n",
      "781                 Py_INCREF(py_V1);\n",
      "782             }\n",
      "783             else if (py_V1 == Py_None)\n",
      "784             {\n",
      "785                 PyErr_SetString(PyExc_TypeError,\n",
      "786                                 \"expected a CudaNdarray, not None\");\n",
      "787                 V1 = NULL;\n",
      "788                 {\n",
      "789         __failure = 2;\n",
      "790         if (!PyErr_Occurred()) {\n",
      "791             PyErr_SetString(PyExc_RuntimeError,\n",
      "792                 \"Unexpected error in an Op's C code. \"\n",
      "793                 \"No Python exception was set.\");\n",
      "794             }\n",
      "795         goto __label_2;};\n",
      "796             }\n",
      "797             else\n",
      "798             {\n",
      "799                 //fprintf(stderr, \"FAILING c_extract CNDA object w refcnt %p %i\\n\", py_V1, (py_V1->ob_refcnt));\n",
      "800                 PyErr_SetString(PyExc_TypeError, \"Argument not a CudaNdarray\");\n",
      "801                 V1 = NULL;\n",
      "802                 {\n",
      "803         __failure = 2;\n",
      "804         if (!PyErr_Occurred()) {\n",
      "805             PyErr_SetString(PyExc_RuntimeError,\n",
      "806                 \"Unexpected error in an Op's C code. \"\n",
      "807                 \"No Python exception was set.\");\n",
      "808             }\n",
      "809         goto __label_2;};\n",
      "810             }\n",
      "811             //std::cerr << \"c_extract done \" << V1 << '\\n';\n",
      "812             \n",
      "813 \n",
      "814         }\n",
      "815         \n",
      "816 {\n",
      "817 \n",
      "818     py_V3 = PyList_GET_ITEM(storage_V3, 0);\n",
      "819     {Py_XINCREF(py_V3);}\n",
      "820     \n",
      "821         assert(py_V3->ob_refcnt >= 2); // There should be at least one ref from the container object,\n",
      "822         // and one ref from the local scope.\n",
      "823 \n",
      "824         if (CudaNdarray_Check(py_V3))\n",
      "825         {\n",
      "826             //fprintf(stderr, \"c_extract CNDA object w refcnt %p %i\\n\", py_V3, (py_V3->ob_refcnt));\n",
      "827             V3 = (CudaNdarray*)py_V3;\n",
      "828             //std::cerr << \"c_extract \" << V3 << '\\n';\n",
      "829         \n",
      "830 \n",
      "831                 if (V3->nd != 4)\n",
      "832                 {\n",
      "833                     PyErr_Format(PyExc_RuntimeError,\n",
      "834                                  \"c_extract: Some CudaNdarray has rank %i, it was supposed to have rank 4\",\n",
      "835                                  V3->nd);\n",
      "836                     V3 = NULL;\n",
      "837                     {\n",
      "838         __failure = 4;\n",
      "839         if (!PyErr_Occurred()) {\n",
      "840             PyErr_SetString(PyExc_RuntimeError,\n",
      "841                 \"Unexpected error in an Op's C code. \"\n",
      "842                 \"No Python exception was set.\");\n",
      "843             }\n",
      "844         goto __label_4;};\n",
      "845                 }\n",
      "846                 //std::cerr << \"c_extract \" << V3 << \" nd check passed\\n\";\n",
      "847             \n",
      "848 \n",
      "849                 assert(V3);\n",
      "850                 Py_INCREF(py_V3);\n",
      "851             }\n",
      "852             else if (py_V3 == Py_None)\n",
      "853             {\n",
      "854                 PyErr_SetString(PyExc_TypeError,\n",
      "855                                 \"expected a CudaNdarray, not None\");\n",
      "856                 V3 = NULL;\n",
      "857                 {\n",
      "858         __failure = 4;\n",
      "859         if (!PyErr_Occurred()) {\n",
      "860             PyErr_SetString(PyExc_RuntimeError,\n",
      "861                 \"Unexpected error in an Op's C code. \"\n",
      "862                 \"No Python exception was set.\");\n",
      "863             }\n",
      "864         goto __label_4;};\n",
      "865             }\n",
      "866             else\n",
      "867             {\n",
      "868                 //fprintf(stderr, \"FAILING c_extract CNDA object w refcnt %p %i\\n\", py_V3, (py_V3->ob_refcnt));\n",
      "869                 PyErr_SetString(PyExc_TypeError, \"Argument not a CudaNdarray\");\n",
      "870                 V3 = NULL;\n",
      "871                 {\n",
      "872         __failure = 4;\n",
      "873         if (!PyErr_Occurred()) {\n",
      "874             PyErr_SetString(PyExc_RuntimeError,\n",
      "875                 \"Unexpected error in an Op's C code. \"\n",
      "876                 \"No Python exception was set.\");\n",
      "877             }\n",
      "878         goto __label_4;};\n",
      "879             }\n",
      "880             //std::cerr << \"c_extract done \" << V3 << '\\n';\n",
      "881             \n",
      "882 \n",
      "883 {\n",
      "884 \n",
      "885     py_V5 = PyList_GET_ITEM(storage_V5, 0);\n",
      "886     {Py_XINCREF(py_V5);}\n",
      "887     \n",
      "888         assert(py_V5->ob_refcnt >= 2); // There should be at least one ref from the container object,\n",
      "889         // and one ref from the local scope.\n",
      "890 \n",
      "891         if (CudaNdarray_Check(py_V5))\n",
      "892         {\n",
      "893             //fprintf(stderr, \"c_extract CNDA object w refcnt %p %i\\n\", py_V5, (py_V5->ob_refcnt));\n",
      "894             V5 = (CudaNdarray*)py_V5;\n",
      "895             //std::cerr << \"c_extract \" << V5 << '\\n';\n",
      "896         \n",
      "897 \n",
      "898                 if (V5->nd != 4)\n",
      "899                 {\n",
      "900                     PyErr_Format(PyExc_RuntimeError,\n",
      "901                                  \"c_extract: Some CudaNdarray has rank %i, it was supposed to have rank 4\",\n",
      "902                                  V5->nd);\n",
      "903                     V5 = NULL;\n",
      "904                     {\n",
      "905         __failure = 6;\n",
      "906         if (!PyErr_Occurred()) {\n",
      "907             PyErr_SetString(PyExc_RuntimeError,\n",
      "908                 \"Unexpected error in an Op's C code. \"\n",
      "909                 \"No Python exception was set.\");\n",
      "910             }\n",
      "911         goto __label_6;};\n",
      "912                 }\n",
      "913                 //std::cerr << \"c_extract \" << V5 << \" nd check passed\\n\";\n",
      "914             \n",
      "915 \n",
      "916                 assert(V5);\n",
      "917                 Py_INCREF(py_V5);\n",
      "918             }\n",
      "919             else if (py_V5 == Py_None)\n",
      "920             {\n",
      "921                 PyErr_SetString(PyExc_TypeError,\n",
      "922                                 \"expected a CudaNdarray, not None\");\n",
      "923                 V5 = NULL;\n",
      "924                 {\n",
      "925         __failure = 6;\n",
      "926         if (!PyErr_Occurred()) {\n",
      "927             PyErr_SetString(PyExc_RuntimeError,\n",
      "928                 \"Unexpected error in an Op's C code. \"\n",
      "929                 \"No Python exception was set.\");\n",
      "930             }\n",
      "931         goto __label_6;};\n",
      "932             }\n",
      "933             else\n",
      "934             {\n",
      "935                 //fprintf(stderr, \"FAILING c_extract CNDA object w refcnt %p %i\\n\", py_V5, (py_V5->ob_refcnt));\n",
      "936                 PyErr_SetString(PyExc_TypeError, \"Argument not a CudaNdarray\");\n",
      "937                 V5 = NULL;\n",
      "938                 {\n",
      "939         __failure = 6;\n",
      "940         if (!PyErr_Occurred()) {\n",
      "941             PyErr_SetString(PyExc_RuntimeError,\n",
      "942                 \"Unexpected error in an Op's C code. \"\n",
      "943                 \"No Python exception was set.\");\n",
      "944             }\n",
      "945         goto __label_6;};\n",
      "946             }\n",
      "947             //std::cerr << \"c_extract done \" << V5 << '\\n';\n",
      "948             \n",
      "949 \n",
      "950 {\n",
      "951 \n",
      "952     py_V7 = PyList_GET_ITEM(storage_V7, 0);\n",
      "953     {Py_XINCREF(py_V7);}\n",
      "954     \n",
      "955         assert(py_V7->ob_refcnt >= 2); // There should be at least one ref from the container object,\n",
      "956         // and one ref from the local scope.\n",
      "957 \n",
      "958         if (CudaNdarray_Check(py_V7))\n",
      "959         {\n",
      "960             //fprintf(stderr, \"c_extract CNDA object w refcnt %p %i\\n\", py_V7, (py_V7->ob_refcnt));\n",
      "961             V7 = (CudaNdarray*)py_V7;\n",
      "962             //std::cerr << \"c_extract \" << V7 << '\\n';\n",
      "963         \n",
      "964 \n",
      "965                 if (V7->nd != 4)\n",
      "966                 {\n",
      "967                     PyErr_Format(PyExc_RuntimeError,\n",
      "968                                  \"c_extract: Some CudaNdarray has rank %i, it was supposed to have rank 4\",\n",
      "969                                  V7->nd);\n",
      "970                     V7 = NULL;\n",
      "971                     {\n",
      "972         __failure = 8;\n",
      "973         if (!PyErr_Occurred()) {\n",
      "974             PyErr_SetString(PyExc_RuntimeError,\n",
      "975                 \"Unexpected error in an Op's C code. \"\n",
      "976                 \"No Python exception was set.\");\n",
      "977             }\n",
      "978         goto __label_8;};\n",
      "979                 }\n",
      "980                 //std::cerr << \"c_extract \" << V7 << \" nd check passed\\n\";\n",
      "981             \n",
      "982 \n",
      "983                 assert(V7);\n",
      "984                 Py_INCREF(py_V7);\n",
      "985             }\n",
      "986             else if (py_V7 == Py_None)\n",
      "987             {\n",
      "988                 PyErr_SetString(PyExc_TypeError,\n",
      "989                                 \"expected a CudaNdarray, not None\");\n",
      "990                 V7 = NULL;\n",
      "991                 {\n",
      "992         __failure = 8;\n",
      "993         if (!PyErr_Occurred()) {\n",
      "994             PyErr_SetString(PyExc_RuntimeError,\n",
      "995                 \"Unexpected error in an Op's C code. \"\n",
      "996                 \"No Python exception was set.\");\n",
      "997             }\n",
      "998         goto __label_8;};\n",
      "999             }\n",
      "1000             else\n",
      "1001             {\n",
      "1002                 //fprintf(stderr, \"FAILING c_extract CNDA object w refcnt %p %i\\n\", py_V7, (py_V7->ob_refcnt));\n",
      "1003                 PyErr_SetString(PyExc_TypeError, \"Argument not a CudaNdarray\");\n",
      "1004                 V7 = NULL;\n",
      "1005                 {\n",
      "1006         __failure = 8;\n",
      "1007         if (!PyErr_Occurred()) {\n",
      "1008             PyErr_SetString(PyExc_RuntimeError,\n",
      "1009                 \"Unexpected error in an Op's C code. \"\n",
      "1010                 \"No Python exception was set.\");\n",
      "1011             }\n",
      "1012         goto __label_8;};\n",
      "1013             }\n",
      "1014             //std::cerr << \"c_extract done \" << V7 << '\\n';\n",
      "1015             \n",
      "1016 \n",
      "1017 {\n",
      "1018 \n",
      "1019     py_V9 = PyList_GET_ITEM(storage_V9, 0);\n",
      "1020     {Py_XINCREF(py_V9);}\n",
      "1021     \n",
      "1022   V9 = (cudnnConvolutionDescriptor_t)PyCapsule_GetPointer(py_V9, NULL);\n",
      "1023   if (V9 == NULL) {\n",
      "1024         __failure = 10;\n",
      "1025         if (!PyErr_Occurred()) {\n",
      "1026             PyErr_SetString(PyExc_RuntimeError,\n",
      "1027                 \"Unexpected error in an Op's C code. \"\n",
      "1028                 \"No Python exception was set.\");\n",
      "1029             }\n",
      "1030         goto __label_10;}\n",
      "1031         \n",
      "1032 {\n",
      "1033 \n",
      "1034     py_V11 = PyList_GET_ITEM(storage_V11, 0);\n",
      "1035     {Py_XINCREF(py_V11);}\n",
      "1036     \n",
      "1037             if (!PyObject_TypeCheck(py_V11, &PyFloat32ArrType_Type))\n",
      "1038             {\n",
      "1039                 PyErr_Format(PyExc_ValueError,\n",
      "1040                     \"Scalar check failed (npy_float32)\");\n",
      "1041                 {\n",
      "1042         __failure = 12;\n",
      "1043         if (!PyErr_Occurred()) {\n",
      "1044             PyErr_SetString(PyExc_RuntimeError,\n",
      "1045                 \"Unexpected error in an Op's C code. \"\n",
      "1046                 \"No Python exception was set.\");\n",
      "1047             }\n",
      "1048         goto __label_12;}\n",
      "1049             }\n",
      "1050             \n",
      "1051         PyArray_ScalarAsCtype(py_V11, &V11);\n",
      "1052         \n",
      "1053 {\n",
      "1054 \n",
      "1055     py_V13 = PyList_GET_ITEM(storage_V13, 0);\n",
      "1056     {Py_XINCREF(py_V13);}\n",
      "1057     \n",
      "1058             if (!PyObject_TypeCheck(py_V13, &PyFloat32ArrType_Type))\n",
      "1059             {\n",
      "1060                 PyErr_Format(PyExc_ValueError,\n",
      "1061                     \"Scalar check failed (npy_float32)\");\n",
      "1062                 {\n",
      "1063         __failure = 14;\n",
      "1064         if (!PyErr_Occurred()) {\n",
      "1065             PyErr_SetString(PyExc_RuntimeError,\n",
      "1066                 \"Unexpected error in an Op's C code. \"\n",
      "1067                 \"No Python exception was set.\");\n",
      "1068             }\n",
      "1069         goto __label_14;}\n",
      "1070             }\n",
      "1071             \n",
      "1072         PyArray_ScalarAsCtype(py_V13, &V13);\n",
      "1073         \n",
      "1074 {\n",
      "1075 // Op class GpuDnnConv\n",
      "1076 \n",
      "1077                 #define APPLY_SPECIFIC(str) str##_node_md48cd7c806151b0105e1fa2b573cc03b_0\n",
      "1078 #define CONV_ALGO CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM\n",
      "1079 #define CHOOSE_ALGO 0\n",
      "1080 #define CHOOSE_ALGO_ONCE 0\n",
      "1081 #define CHOOSE_ALGO_TIME 0\n",
      "1082 #define CONV_INPLACE 1\n",
      "1083                 {\n",
      "1084                   if (APPLY_SPECIFIC(conv_fwd)(V3, V5, V7, V9, V11, V13, &V1) != 0) {\n",
      "1085                     {\n",
      "1086         __failure = 15;\n",
      "1087         if (!PyErr_Occurred()) {\n",
      "1088             PyErr_SetString(PyExc_RuntimeError,\n",
      "1089                 \"Unexpected error in an Op's C code. \"\n",
      "1090                 \"No Python exception was set.\");\n",
      "1091             }\n",
      "1092         goto __label_15;}\n",
      "1093                   }\n",
      "1094                 }\n",
      "1095                 #undef APPLY_SPECIFIC\n",
      "1096 #undef CONV_ALGO\n",
      "1097 #undef CHOOSE_ALGO\n",
      "1098 #undef CHOOSE_ALGO_ONCE\n",
      "1099 #undef CHOOSE_ALGO_TIME\n",
      "1100 #undef CONV_INPLACE\n",
      "1101                 __label_15:\n",
      "1102 \n",
      "1103 double __DUMMY_15;\n",
      "1104 \n",
      "1105 }\n",
      "1106 __label_14:\n",
      "1107 \n",
      "1108     {Py_XDECREF(py_V13);}\n",
      "1109     \n",
      "1110 double __DUMMY_14;\n",
      "1111 \n",
      "1112 }\n",
      "1113 __label_12:\n",
      "1114 \n",
      "1115     {Py_XDECREF(py_V11);}\n",
      "1116     \n",
      "1117 double __DUMMY_12;\n",
      "1118 \n",
      "1119 }\n",
      "1120 __label_10:\n",
      "1121 \n",
      "1122     {Py_XDECREF(py_V9);}\n",
      "1123     \n",
      "1124 double __DUMMY_10;\n",
      "1125 \n",
      "1126 }\n",
      "1127 __label_8:\n",
      "1128 \n",
      "1129         //std::cerr << \"cleanup \" << py_V7 << \" \" << V7 << \"\\n\";\n",
      "1130         //fprintf(stderr, \"c_cleanup CNDA py_object w refcnt %p %i\\n\", py_V7, (py_V7->ob_refcnt));\n",
      "1131         if (V7)\n",
      "1132         {\n",
      "1133             //fprintf(stderr, \"c_cleanup CNDA cn_object w refcnt %p %i\\n\", V7, (V7->ob_refcnt));\n",
      "1134             Py_XDECREF(V7);\n",
      "1135         }\n",
      "1136         //std::cerr << \"cleanup done\" << py_V7 << \"\\n\";\n",
      "1137         \n",
      "1138     {Py_XDECREF(py_V7);}\n",
      "1139     \n",
      "1140 double __DUMMY_8;\n",
      "1141 \n",
      "1142 }\n",
      "1143 __label_6:\n",
      "1144 \n",
      "1145         //std::cerr << \"cleanup \" << py_V5 << \" \" << V5 << \"\\n\";\n",
      "1146         //fprintf(stderr, \"c_cleanup CNDA py_object w refcnt %p %i\\n\", py_V5, (py_V5->ob_refcnt));\n",
      "1147         if (V5)\n",
      "1148         {\n",
      "1149             //fprintf(stderr, \"c_cleanup CNDA cn_object w refcnt %p %i\\n\", V5, (V5->ob_refcnt));\n",
      "1150             Py_XDECREF(V5);\n",
      "1151         }\n",
      "1152         //std::cerr << \"cleanup done\" << py_V5 << \"\\n\";\n",
      "1153         \n",
      "1154     {Py_XDECREF(py_V5);}\n",
      "1155     \n",
      "1156 double __DUMMY_6;\n",
      "1157 \n",
      "1158 }\n",
      "1159 __label_4:\n",
      "1160 \n",
      "1161         //std::cerr << \"cleanup \" << py_V3 << \" \" << V3 << \"\\n\";\n",
      "1162         //fprintf(stderr, \"c_cleanup CNDA py_object w refcnt %p %i\\n\", py_V3, (py_V3->ob_refcnt));\n",
      "1163         if (V3)\n",
      "1164         {\n",
      "1165             //fprintf(stderr, \"c_cleanup CNDA cn_object w refcnt %p %i\\n\", V3, (V3->ob_refcnt));\n",
      "1166             Py_XDECREF(V3);\n",
      "1167         }\n",
      "1168         //std::cerr << \"cleanup done\" << py_V3 << \"\\n\";\n",
      "1169         \n",
      "1170     {Py_XDECREF(py_V3);}\n",
      "1171     \n",
      "1172 double __DUMMY_4;\n",
      "1173 \n",
      "1174 }\n",
      "1175 __label_2:\n",
      "1176 \n",
      "1177     if (!__failure) {\n",
      "1178       \n",
      "1179         //std::cerr << \"sync\\n\";\n",
      "1180         if (NULL == V1) {\n",
      "1181             // failure: sync None to storage\n",
      "1182             Py_XDECREF(py_V1);\n",
      "1183             py_V1 = Py_None;\n",
      "1184             Py_INCREF(py_V1);\n",
      "1185         }\n",
      "1186         else\n",
      "1187         {\n",
      "1188             if (py_V1 != (PyObject*)V1)\n",
      "1189             {\n",
      "1190                 Py_XDECREF(py_V1);\n",
      "1191                 py_V1 = (PyObject*)V1;\n",
      "1192                 Py_INCREF(py_V1);\n",
      "1193             }\n",
      "1194             assert(py_V1->ob_refcnt);\n",
      "1195         }\n",
      "1196         \n",
      "1197       PyObject* old = PyList_GET_ITEM(storage_V1, 0);\n",
      "1198       {Py_XINCREF(py_V1);}\n",
      "1199       PyList_SET_ITEM(storage_V1, 0, py_V1);\n",
      "1200       {Py_XDECREF(old);}\n",
      "1201     }\n",
      "1202     \n",
      "1203         //std::cerr << \"cleanup \" << py_V1 << \" \" << V1 << \"\\n\";\n",
      "1204         //fprintf(stderr, \"c_cleanup CNDA py_object w refcnt %p %i\\n\", py_V1, (py_V1->ob_refcnt));\n",
      "1205         if (V1)\n",
      "1206         {\n",
      "1207             //fprintf(stderr, \"c_cleanup CNDA cn_object w refcnt %p %i\\n\", V1, (V1->ob_refcnt));\n",
      "1208             Py_XDECREF(V1);\n",
      "1209         }\n",
      "1210         //std::cerr << \"cleanup done\" << py_V1 << \"\\n\";\n",
      "1211         \n",
      "1212     {Py_XDECREF(py_V1);}\n",
      "1213     \n",
      "1214 double __DUMMY_2;\n",
      "1215 \n",
      "1216 }\n",
      "1217 \n",
      "1218             \n",
      "1219         if (__failure) {\n",
      "1220             // When there is a failure, this code puts the exception\n",
      "1221             // in __ERROR.\n",
      "1222             PyObject* err_type = NULL;\n",
      "1223             PyObject* err_msg = NULL;\n",
      "1224             PyObject* err_traceback = NULL;\n",
      "1225             PyErr_Fetch(&err_type, &err_msg, &err_traceback);\n",
      "1226             if (!err_type) {err_type = Py_None;Py_INCREF(Py_None);}\n",
      "1227             if (!err_msg) {err_msg = Py_None; Py_INCREF(Py_None);}\n",
      "1228             if (!err_traceback) {err_traceback = Py_None; Py_INCREF(Py_None);}\n",
      "1229             PyObject* old_err_type = PyList_GET_ITEM(__ERROR, 0);\n",
      "1230             PyObject* old_err_msg = PyList_GET_ITEM(__ERROR, 1);\n",
      "1231             PyObject* old_err_traceback = PyList_GET_ITEM(__ERROR, 2);\n",
      "1232             PyList_SET_ITEM(__ERROR, 0, err_type);\n",
      "1233             PyList_SET_ITEM(__ERROR, 1, err_msg);\n",
      "1234             PyList_SET_ITEM(__ERROR, 2, err_traceback);\n",
      "1235             {Py_XDECREF(old_err_type);}\n",
      "1236             {Py_XDECREF(old_err_msg);}\n",
      "1237             {Py_XDECREF(old_err_traceback);}\n",
      "1238         }\n",
      "1239         // The failure code is returned to index what code block failed.\n",
      "1240         return __failure;\n",
      "1241         \n",
      "1242         }\n",
      "1243     };\n",
      "1244     }\n",
      "1245     \n",
      "1246 \n",
      "1247         static int __struct_compiled_op_md48cd7c806151b0105e1fa2b573cc03b_executor(__struct_compiled_op_md48cd7c806151b0105e1fa2b573cc03b *self) {\n",
      "1248             return self->run();\n",
      "1249         }\n",
      "1250 \n",
      "1251         static void __struct_compiled_op_md48cd7c806151b0105e1fa2b573cc03b_destructor(PyObject *capsule) {\n",
      "1252             __struct_compiled_op_md48cd7c806151b0105e1fa2b573cc03b *self = (__struct_compiled_op_md48cd7c806151b0105e1fa2b573cc03b *)PyCapsule_GetContext(capsule);\n",
      "1253             delete self;\n",
      "1254         }\n",
      "1255         \n",
      "1256 //////////////////////\n",
      "1257 ////  Functions\n",
      "1258 //////////////////////\n",
      "1259 static PyObject * instantiate(PyObject * self, PyObject *argtuple) {\n",
      "1260   assert(PyTuple_Check(argtuple));\n",
      "1261   if (8 != PyTuple_Size(argtuple)){ \n",
      "1262      PyErr_Format(PyExc_TypeError, \"Wrong number of arguments, expected 8, got %i\", (int)PyTuple_Size(argtuple));\n",
      "1263      return NULL;\n",
      "1264   }\n",
      "1265   __struct_compiled_op_md48cd7c806151b0105e1fa2b573cc03b* struct_ptr = new __struct_compiled_op_md48cd7c806151b0105e1fa2b573cc03b();\n",
      "1266   if (struct_ptr->init( PyTuple_GET_ITEM(argtuple, 0),PyTuple_GET_ITEM(argtuple, 1),PyTuple_GET_ITEM(argtuple, 2),PyTuple_GET_ITEM(argtuple, 3),PyTuple_GET_ITEM(argtuple, 4),PyTuple_GET_ITEM(argtuple, 5),PyTuple_GET_ITEM(argtuple, 6),PyTuple_GET_ITEM(argtuple, 7) ) != 0) {\n",
      "1267     delete struct_ptr;\n",
      "1268     return NULL;\n",
      "1269   }\n",
      "1270     PyObject* thunk = PyCapsule_New((void*)(&__struct_compiled_op_md48cd7c806151b0105e1fa2b573cc03b_executor), NULL, __struct_compiled_op_md48cd7c806151b0105e1fa2b573cc03b_destructor);\n",
      "1271     if (thunk != NULL && PyCapsule_SetContext(thunk, struct_ptr) != 0) {\n",
      "1272         PyErr_Clear();\n",
      "1273         Py_DECREF(thunk);\n",
      "1274         thunk = NULL;\n",
      "1275     }\n",
      "1276 \n",
      "1277   return thunk; }\n",
      "1278 \n",
      "1279 //////////////////////\n",
      "1280 ////  Module init\n",
      "1281 //////////////////////\n",
      "1282 static PyMethodDef MyMethods[] = {\n",
      "1283 \t{\"instantiate\", instantiate, METH_VARARGS, \"undocumented\"} ,\n",
      "1284 \t{NULL, NULL, 0, NULL}\n",
      "1285 };\n",
      "1286 static struct PyModuleDef moduledef = {\n",
      "1287       PyModuleDef_HEAD_INIT,\n",
      "1288       \"md48cd7c806151b0105e1fa2b573cc03b\",\n",
      "1289       NULL,\n",
      "1290       -1,\n",
      "1291       MyMethods,\n",
      "1292 };\n",
      "1293 \n",
      "1294 PyMODINIT_FUNC PyInit_md48cd7c806151b0105e1fa2b573cc03b(void) {\n",
      "1295    import_array();\n",
      "1296    \n",
      "1297 \n",
      "1298 {\n",
      "1299   cudnnStatus_t err;\n",
      "1300   if ((err = cudnnCreate(&_handle)) != CUDNN_STATUS_SUCCESS) {\n",
      "1301     PyErr_Format(PyExc_RuntimeError, \"could not create cuDNN handle: %s\",\n",
      "1302 \t\t cudnnGetErrorString(err));\n",
      "1303 #if PY_MAJOR_VERSION >= 3\n",
      "1304     return NULL;\n",
      "1305 #else\n",
      "1306     return;\n",
      "1307 #endif\n",
      "1308   }\n",
      "1309 }\n",
      "1310 \n",
      "1311     PyObject *m = PyModule_Create(&moduledef);\n",
      "1312     return m;\n",
      "1313 }\n",
      "1314 \n",
      "===============================\n",
      "In file included from mod.cu:4:0:\n",
      "/home/anirudh/anaconda/envs/fyp/lib/python3.5/site-packages/theano/sandbox/cuda/cuda_ndarray.cuh:17:0: warning: \"PyString_Check\" redefined\n",
      " #define PyString_Check PyUnicode_Check\n",
      " ^\n",
      "In file included from /home/anirudh/anaconda/envs/fyp/lib/python3.5/site-packages/theano/sandbox/cuda/cuda_ndarray.cuh:11:0,\n",
      "                 from mod.cu:4:\n",
      "/home/anirudh/anaconda/envs/fyp/lib/python3.5/site-packages/numpy/core/include/numpy/npy_3kcompat.h:71:0: note: this is the location of the previous definition\n",
      " #define PyString_Check PyBytes_Check\n",
      " ^\n",
      "In file included from mod.cu:4:0:\n",
      "/home/anirudh/anaconda/envs/fyp/lib/python3.5/site-packages/theano/sandbox/cuda/cuda_ndarray.cuh:18:0: warning: \"PyString_FromString\" redefined\n",
      " #define PyString_FromString PyUnicode_FromString\n",
      " ^\n",
      "In file included from /home/anirudh/anaconda/envs/fyp/lib/python3.5/site-packages/theano/sandbox/cuda/cuda_ndarray.cuh:11:0,\n",
      "                 from mod.cu:4:\n",
      "/home/anirudh/anaconda/envs/fyp/lib/python3.5/site-packages/numpy/core/include/numpy/npy_3kcompat.h:73:0: note: this is the location of the previous definition\n",
      " #define PyString_FromString PyBytes_FromString\n",
      " ^\n",
      "In file included from mod.cu:4:0:\n",
      "/home/anirudh/anaconda/envs/fyp/lib/python3.5/site-packages/theano/sandbox/cuda/cuda_ndarray.cuh:19:0: warning: \"PyString_AsString\" redefined\n",
      " #define PyString_AsString PyUnicode_AsUTF8\n",
      " ^\n",
      "In file included from /home/anirudh/anaconda/envs/fyp/lib/python3.5/site-packages/theano/sandbox/cuda/cuda_ndarray.cuh:11:0,\n",
      "                 from mod.cu:4:\n",
      "/home/anirudh/anaconda/envs/fyp/lib/python3.5/site-packages/numpy/core/include/numpy/npy_3kcompat.h:80:0: note: this is the location of the previous definition\n",
      " #define PyString_AsString PyBytes_AsString\n",
      " ^\n",
      "In file included from mod.cu:4:0:\n",
      "/home/anirudh/anaconda/envs/fyp/lib/python3.5/site-packages/theano/sandbox/cuda/cuda_ndarray.cuh:20:0: warning: \"PyString_FromStringAndSize\" redefined\n",
      " #define PyString_FromStringAndSize PyUnicode_FromStringAndSize\n",
      " ^\n",
      "In file included from /home/anirudh/anaconda/envs/fyp/lib/python3.5/site-packages/theano/sandbox/cuda/cuda_ndarray.cuh:11:0,\n",
      "                 from mod.cu:4:\n",
      "/home/anirudh/anaconda/envs/fyp/lib/python3.5/site-packages/numpy/core/include/numpy/npy_3kcompat.h:74:0: note: this is the location of the previous definition\n",
      " #define PyString_FromStringAndSize PyBytes_FromStringAndSize\n",
      " ^\n",
      "In file included from mod.cu:4:0:\n",
      "/home/anirudh/anaconda/envs/fyp/lib/python3.5/site-packages/theano/sandbox/cuda/cuda_ndarray.cuh:21:0: warning: \"PyString_Size\" redefined\n",
      " #define PyString_Size PyUnicode_GET_SIZE\n",
      " ^\n",
      "In file included from /home/anirudh/anaconda/envs/fyp/lib/python3.5/site-packages/theano/sandbox/cuda/cuda_ndarray.cuh:11:0,\n",
      "                 from mod.cu:4:\n",
      "/home/anirudh/anaconda/envs/fyp/lib/python3.5/site-packages/numpy/core/include/numpy/npy_3kcompat.h:82:0: note: this is the location of the previous definition\n",
      " #define PyString_Size PyBytes_Size\n",
      " ^\n",
      "mod.cu(77): error: identifier \"cudnnSetFilterNdDescriptor_v4\" is undefined\n",
      "mod.cu(326): warning: conversion from a string literal to \"char *\" is deprecated\n",
      "mod.cu(329): warning: conversion from a string literal to \"char *\" is deprecated\n",
      "mod.cu(332): warning: conversion from a string literal to \"char *\" is deprecated\n",
      "mod.cu(335): warning: conversion from a string literal to \"char *\" is deprecated\n",
      "mod.cu(338): warning: conversion from a string literal to \"char *\" is deprecated\n",
      "mod.cu(341): warning: conversion from a string literal to \"char *\" is deprecated\n",
      "mod.cu(345): warning: conversion from a string literal to \"char *\" is deprecated\n",
      "1 error detected in the compilation of \"/tmp/tmpxft_00004ff6_00000000-9_mod.cpp1.ii\".\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "('The following error happened while compiling the node', GpuDnnConv{algo='small', inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuAllocEmpty.0, GpuDnnConvDesc{border_mode='valid', subsample=(1, 1), conv_mode='conv', precision='float32'}.0, Constant{1.0}, Constant{0.0}), '\\n', 'nvcc return status', 2, 'for cmd', 'nvcc -shared -O3 -Xlinker -rpath,/usr/local/cuda-8.0/lib64 -use_fast_math -arch=sm_61 -m64 -Xcompiler -fno-math-errno,-Wno-unused-label,-Wno-unused-variable,-Wno-write-strings,-DCUDA_NDARRAY_CUH=mc72d035fdf91890f3b36710688069b2e,-DNPY_NO_DEPRECATED_API=NPY_1_7_API_VERSION,-fPIC,-fvisibility=hidden -Xlinker -rpath,/home/anirudh/.theano/compiledir_Linux-4.13--generic-x86_64-with-debian-stretch-sid-x86_64-3.5.4-64/cuda_ndarray -I/home/anirudh/.theano/compiledir_Linux-4.13--generic-x86_64-with-debian-stretch-sid-x86_64-3.5.4-64/cuda_ndarray -I/usr/local/cuda-8.0/include -I/home/anirudh/anaconda/envs/fyp/lib/python3.5/site-packages/theano/sandbox/cuda -I/home/anirudh/anaconda/envs/fyp/lib/python3.5/site-packages/numpy/core/include -I/home/anirudh/anaconda/envs/fyp/include/python3.5m -I/home/anirudh/anaconda/envs/fyp/lib/python3.5/site-packages/theano/gof -L/home/anirudh/.theano/compiledir_Linux-4.13--generic-x86_64-with-debian-stretch-sid-x86_64-3.5.4-64/cuda_ndarray -L/home/anirudh/anaconda/envs/fyp/lib -o /home/anirudh/.theano/compiledir_Linux-4.13--generic-x86_64-with-debian-stretch-sid-x86_64-3.5.4-64/tmpidynwxhc/md48cd7c806151b0105e1fa2b573cc03b.so mod.cu -lcudart -lcublas -lcuda_ndarray -lcudnn -lpython3.5m', \"[GpuDnnConv{algo='small', inplace=True}(<CudaNdarrayType(float32, 4D)>, <CudaNdarrayType(float32, 4D)>, <CudaNdarrayType(float32, 4D)>, <CDataType{cudnnConvolutionDescriptor_t}>, Constant{1.0}, Constant{0.0})]\")",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-c4375a1c268b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    165\u001b[0m                     \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m                     \u001b[0mnb_val_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnb_validation_samples\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m                     callbacks = [checkpoint])\n\u001b[0m",
      "\u001b[0;32m~/anaconda/envs/fyp/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/fyp/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1254\u001b[0m                                         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1255\u001b[0m                                         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1256\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/fyp/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/fyp/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2024\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2025\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2026\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2027\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdo_validation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2028\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_test_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/fyp/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_make_train_function\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    975\u001b[0m                                                  \u001b[0mupdates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m                                                  \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train_function'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m                                                  **self._function_kwargs)\n\u001b[0m\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_test_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/fyp/lib/python3.5/site-packages/keras/backend/theano_backend.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(inputs, outputs, updates, **kwargs)\u001b[0m\n\u001b[1;32m   1234\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Invalid argument \"%s\" passed to K.function with Theano backend'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/fyp/lib/python3.5/site-packages/keras/backend/theano_backend.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputs, outputs, updates, name, **kwargs)\u001b[0m\n\u001b[1;32m   1220\u001b[0m                                         \u001b[0mon_unused_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                                         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1222\u001b[0;31m                                         **kwargs)\n\u001b[0m\u001b[1;32m   1223\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/fyp/lib/python3.5/site-packages/theano/compile/function.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(inputs, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input)\u001b[0m\n\u001b[1;32m    324\u001b[0m                    \u001b[0mon_unused_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m                    \u001b[0mprofile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                    output_keys=output_keys)\n\u001b[0m\u001b[1;32m    327\u001b[0m     \u001b[0;31m# We need to add the flag check_aliased inputs if we have any mutable or\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;31m# borrowed used defined inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/fyp/lib/python3.5/site-packages/theano/compile/pfunc.py\u001b[0m in \u001b[0;36mpfunc\u001b[0;34m(params, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input, output_keys)\u001b[0m\n\u001b[1;32m    484\u001b[0m                          \u001b[0maccept_inplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_inplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m                          \u001b[0mprofile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_unused_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m                          output_keys=output_keys)\n\u001b[0m\u001b[1;32m    487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/fyp/lib/python3.5/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36morig_function\u001b[0;34m(inputs, outputs, mode, accept_inplace, name, profile, on_unused_input, output_keys)\u001b[0m\n\u001b[1;32m   1793\u001b[0m                    \u001b[0mon_unused_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1794\u001b[0m                    \u001b[0moutput_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1795\u001b[0;31m             defaults)\n\u001b[0m\u001b[1;32m   1796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1797\u001b[0m     \u001b[0mt2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/fyp/lib/python3.5/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, input_storage, trustme, storage_map)\u001b[0m\n\u001b[1;32m   1659\u001b[0m             \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlimit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile_limit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m             _fn, _i, _o = self.linker.make_thunk(\n\u001b[0;32m-> 1661\u001b[0;31m                 input_storage=input_storage_lists, storage_map=storage_map)\n\u001b[0m\u001b[1;32m   1662\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1663\u001b[0m             \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlimit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlimit_orig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/fyp/lib/python3.5/site-packages/theano/gof/link.py\u001b[0m in \u001b[0;36mmake_thunk\u001b[0;34m(self, input_storage, output_storage, storage_map)\u001b[0m\n\u001b[1;32m    697\u001b[0m         return self.make_all(input_storage=input_storage,\n\u001b[1;32m    698\u001b[0m                              \u001b[0moutput_storage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_storage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                              storage_map=storage_map)[:3]\n\u001b[0m\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmake_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/fyp/lib/python3.5/site-packages/theano/gof/vm.py\u001b[0m in \u001b[0;36mmake_all\u001b[0;34m(self, profiler, input_storage, output_storage, storage_map)\u001b[0m\n\u001b[1;32m   1045\u001b[0m                                                  \u001b[0mcompute_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m                                                  \u001b[0mno_recycling\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m                                                  impl=impl))\n\u001b[0m\u001b[1;32m   1048\u001b[0m                 \u001b[0mlinker_make_thunk_time\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mthunk_start\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthunks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lazy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/fyp/lib/python3.5/site-packages/theano/gof/op.py\u001b[0m in \u001b[0;36mmake_thunk\u001b[0;34m(self, node, storage_map, compute_map, no_recycling, impl)\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m                 return self.make_c_thunk(node, storage_map, compute_map,\n\u001b[0;32m--> 935\u001b[0;31m                                          no_recycling)\n\u001b[0m\u001b[1;32m    936\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mNotImplementedError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMethodNotDefined\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m                 \u001b[0;31m# We requested the c code, so don't catch the error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/fyp/lib/python3.5/site-packages/theano/gof/op.py\u001b[0m in \u001b[0;36mmake_c_thunk\u001b[0;34m(self, node, storage_map, compute_map, no_recycling)\u001b[0m\n\u001b[1;32m    837\u001b[0m         \u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Trying CLinker.make_thunk'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m         outputs = cl.make_thunk(input_storage=node_input_storage,\n\u001b[0;32m--> 839\u001b[0;31m                                 output_storage=node_output_storage)\n\u001b[0m\u001b[1;32m    840\u001b[0m         \u001b[0mfill_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_input_filters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_output_filters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/fyp/lib/python3.5/site-packages/theano/gof/cc.py\u001b[0m in \u001b[0;36mmake_thunk\u001b[0;34m(self, input_storage, output_storage, storage_map, keep_lock)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         cthunk, in_storage, out_storage, error_storage = self.__compile__(\n\u001b[1;32m   1189\u001b[0m             \u001b[0minput_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1190\u001b[0;31m             keep_lock=keep_lock)\n\u001b[0m\u001b[1;32m   1191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_CThunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcthunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_tasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/fyp/lib/python3.5/site-packages/theano/gof/cc.py\u001b[0m in \u001b[0;36m__compile__\u001b[0;34m(self, input_storage, output_storage, storage_map, keep_lock)\u001b[0m\n\u001b[1;32m   1129\u001b[0m                                     \u001b[0moutput_storage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m                                     \u001b[0mstorage_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1131\u001b[0;31m                                     keep_lock=keep_lock)\n\u001b[0m\u001b[1;32m   1132\u001b[0m         return (thunk,\n\u001b[1;32m   1133\u001b[0m                 [link.Container(input, storage) for input, storage in\n",
      "\u001b[0;32m~/anaconda/envs/fyp/lib/python3.5/site-packages/theano/gof/cc.py\u001b[0m in \u001b[0;36mcthunk_factory\u001b[0;34m(self, error_storage, in_storage, out_storage, storage_map, keep_lock)\u001b[0m\n\u001b[1;32m   1584\u001b[0m                 \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1585\u001b[0m             module = get_module_cache().module_from_key(\n\u001b[0;32m-> 1586\u001b[0;31m                 key=key, lnk=self, keep_lock=keep_lock)\n\u001b[0m\u001b[1;32m   1587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1588\u001b[0m         \u001b[0mvars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morphans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/fyp/lib/python3.5/site-packages/theano/gof/cmodule.py\u001b[0m in \u001b[0;36mmodule_from_key\u001b[0;34m(self, key, lnk, keep_lock)\u001b[0m\n\u001b[1;32m   1157\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m                 \u001b[0mlocation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdlimport_workdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1159\u001b[0;31m                 \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlnk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile_cmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1160\u001b[0m                 \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/fyp/lib/python3.5/site-packages/theano/gof/cc.py\u001b[0m in \u001b[0;36mcompile_cmodule\u001b[0;34m(self, location)\u001b[0m\n\u001b[1;32m   1487\u001b[0m                 \u001b[0mlib_dirs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib_dirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m                 \u001b[0mlibs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlibs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1489\u001b[0;31m                 preargs=preargs)\n\u001b[0m\u001b[1;32m   1490\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1491\u001b[0m             \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/fyp/lib/python3.5/site-packages/theano/sandbox/cuda/nvcc_compiler.py\u001b[0m in \u001b[0;36mcompile_str\u001b[0;34m(module_name, src_code, location, include_dirs, lib_dirs, libs, preargs, rpaths, py_module, hide_symbols)\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m             raise Exception('nvcc return status', p.returncode,\n\u001b[0;32m--> 405\u001b[0;31m                             'for cmd', ' '.join(cmd))\n\u001b[0m\u001b[1;32m    406\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompilation_warning\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnvcc_stdout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnvcc_stdout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: ('The following error happened while compiling the node', GpuDnnConv{algo='small', inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuAllocEmpty.0, GpuDnnConvDesc{border_mode='valid', subsample=(1, 1), conv_mode='conv', precision='float32'}.0, Constant{1.0}, Constant{0.0}), '\\n', 'nvcc return status', 2, 'for cmd', 'nvcc -shared -O3 -Xlinker -rpath,/usr/local/cuda-8.0/lib64 -use_fast_math -arch=sm_61 -m64 -Xcompiler -fno-math-errno,-Wno-unused-label,-Wno-unused-variable,-Wno-write-strings,-DCUDA_NDARRAY_CUH=mc72d035fdf91890f3b36710688069b2e,-DNPY_NO_DEPRECATED_API=NPY_1_7_API_VERSION,-fPIC,-fvisibility=hidden -Xlinker -rpath,/home/anirudh/.theano/compiledir_Linux-4.13--generic-x86_64-with-debian-stretch-sid-x86_64-3.5.4-64/cuda_ndarray -I/home/anirudh/.theano/compiledir_Linux-4.13--generic-x86_64-with-debian-stretch-sid-x86_64-3.5.4-64/cuda_ndarray -I/usr/local/cuda-8.0/include -I/home/anirudh/anaconda/envs/fyp/lib/python3.5/site-packages/theano/sandbox/cuda -I/home/anirudh/anaconda/envs/fyp/lib/python3.5/site-packages/numpy/core/include -I/home/anirudh/anaconda/envs/fyp/include/python3.5m -I/home/anirudh/anaconda/envs/fyp/lib/python3.5/site-packages/theano/gof -L/home/anirudh/.theano/compiledir_Linux-4.13--generic-x86_64-with-debian-stretch-sid-x86_64-3.5.4-64/cuda_ndarray -L/home/anirudh/anaconda/envs/fyp/lib -o /home/anirudh/.theano/compiledir_Linux-4.13--generic-x86_64-with-debian-stretch-sid-x86_64-3.5.4-64/tmpidynwxhc/md48cd7c806151b0105e1fa2b573cc03b.so mod.cu -lcudart -lcublas -lcuda_ndarray -lcudnn -lpython3.5m', \"[GpuDnnConv{algo='small', inplace=True}(<CudaNdarrayType(float32, 4D)>, <CudaNdarrayType(float32, 4D)>, <CudaNdarrayType(float32, 4D)>, <CDataType{cudnnConvolutionDescriptor_t}>, Constant{1.0}, Constant{0.0})]\")"
     ]
    }
   ],
   "source": [
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model \n",
    "from keras.layers import Input, Dropout, Flatten, Dense, GlobalAveragePooling2D, ZeroPadding2D, Convolution2D, MaxPooling2D\n",
    "from keras import backend as k \n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "\n",
    "import os\n",
    "import importlib\n",
    "\n",
    "\n",
    "img_width, img_height = 224, 224\n",
    "train_data_dir = \"/media/anirudh/Data/Code/Dpaas/KERAS_FACE_RECOGNITION/data copy/data copy/train\"\n",
    "validation_data_dir = \"/media/anirudh/Data/Code/Dpaas/KERAS_FACE_RECOGNITION/data copy/data copy/val\"\n",
    "nb_train_samples = 1000\n",
    "nb_validation_samples = 200 \n",
    "batch_size = 16\n",
    "epochs = 100\n",
    "weights_path = 'vgg-face-keras-fc.h5'\n",
    "\n",
    "# model = applications.VGG16(weights = \"vgg-face-keras-fc.h5\", include_top=True, input_shape = (3, img_width, img_height))\n",
    "model = Sequential()\n",
    "model.add(ZeroPadding2D((1, 1), input_shape=(3, img_height, img_width)))\n",
    "model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "# Add Fully Connected Layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2622, activation='softmax'))\n",
    "# out = Dense(2622, activation='softmax', name='fc8')(fc7_drop)\n",
    "\n",
    "# model = Model(input=img, output=out)\n",
    "model.load_weights(weights_path)\n",
    "\n",
    "# Truncate and replace softmax layer for transfer learning\n",
    "model.layers.pop()\n",
    "model.outputs = [model.layers[-1].output]\n",
    "model.layers[-1].outbound_nodes = []\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\"\"\"\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "input_1 (InputLayer)         (None, 256, 256, 3)       0         \n",
    "_________________________________________________________________\n",
    "block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      \n",
    "_________________________________________________________________\n",
    "block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     \n",
    "_________________________________________________________________\n",
    "block1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         \n",
    "_________________________________________________________________\n",
    "block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     \n",
    "_________________________________________________________________\n",
    "block2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    \n",
    "_________________________________________________________________\n",
    "block2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         \n",
    "_________________________________________________________________\n",
    "block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    \n",
    "_________________________________________________________________\n",
    "block3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    \n",
    "_________________________________________________________________\n",
    "block3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    \n",
    "_________________________________________________________________\n",
    "block3_conv4 (Conv2D)        (None, 64, 64, 256)       590080    \n",
    "_________________________________________________________________\n",
    "block3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         \n",
    "_________________________________________________________________\n",
    "block4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   \n",
    "_________________________________________________________________\n",
    "block4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
    "_________________________________________________________________\n",
    "block4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
    "_________________________________________________________________\n",
    "block4_conv4 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
    "_________________________________________________________________\n",
    "block4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         \n",
    "_________________________________________________________________\n",
    "block5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
    "_________________________________________________________________\n",
    "block5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
    "_________________________________________________________________\n",
    "block5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
    "_________________________________________________________________\n",
    "block5_conv4 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
    "_________________________________________________________________\n",
    "block5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
    "=================================================================\n",
    "Total params: 20,024,384.0\n",
    "Trainable params: 20,024,384.0\n",
    "Non-trainable params: 0.0\n",
    "\"\"\"\n",
    "\n",
    "# Freeze the layers which you don't want to train. Here I am freezing the first 5 layers.\n",
    "for layer in model.layers[:13]:\n",
    "    layer.trainable = False\n",
    "\n",
    "#Adding custom Layers \n",
    "# x = model.output\n",
    "# x = Flatten()(x)\n",
    "# x = Dense(1024, activation=\"relu\")(x)\n",
    "# x = Dropout(0.5)(x)\n",
    "# x = Dense(1024, activation=\"relu\")(x)\n",
    "# predictions = Dense(3, activation=\"softmax\")(x)\n",
    "\n",
    "# creating the final model \n",
    "# model = Model(input = model.input, output = out)\n",
    "\n",
    "# compile the model \n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.Adam(lr=0.000001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False), metrics=[\"accuracy\"])\n",
    "\n",
    "# Initiate the train and test generators with data Augumentation \n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,horizontal_flip = True,fill_mode = \"nearest\",zoom_range = 0.3,width_shift_range = 0.3,height_shift_range=0.3,rotation_range=30)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255,horizontal_flip = True,fill_mode = \"nearest\",zoom_range = 0.3,width_shift_range = 0.3,height_shift_range=0.3,rotation_range=30)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_data_dir,target_size = (img_height, img_width),batch_size = batch_size, class_mode = \"categorical\", shuffle=True)\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(validation_data_dir,target_size = (img_height, img_width),class_mode = \"categorical\")\n",
    "\n",
    "# Save the model according to the conditions  \n",
    "checkpoint = ModelCheckpoint(\"vgg16_face.h5\", monitor='val_acc', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "# early = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=0, mode='auto')\n",
    "\n",
    "\n",
    "# Train the model \n",
    "model.fit_generator(train_generator,\n",
    "                    steps_per_epoch = nb_train_samples/batch_size,\n",
    "                    epochs = epochs,\n",
    "                    validation_data = validation_generator,\n",
    "                    nb_val_samples = nb_validation_samples/batch_size,\n",
    "                    callbacks = [checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
